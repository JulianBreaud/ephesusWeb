
####################################################################
### IMPORTS
####################################################################

from re import S
import streamlit as st
import numpy as np
import pandas as pd
import requests
from PIL import Image
from annotated_text import annotated_text
import streamlit.components.v1 as components

import os
import json
from os import listdir
from os.path import isfile, join

import spacy
from spacy_streamlit import visualize, visualize_ner, visualize_textcat, visualize_tokens, process_text

from spacy.vocab import Vocab
from spacy.tokens import Doc
import base64

####################################################################
### SIDEBAR & CONFIG
####################################################################

st.set_page_config(
            page_title="Projet Ephesus", # => Quick reference - Streamlit
            page_icon="",#on a choisi le logo standard mais on peut mettre au chose "üêç",
            layout="wide",
            initial_sidebar_state="auto") # collapsed


image = Image.open('images/medical.png')
st.sidebar.image(image, caption="", use_column_width=False)
st.sidebar.markdown("")

pages = ('Projet Ephesus', 'D√©mo')#('Projet Ephesus', 'D√©mo', 'Run', 'Et pour finir')
direction = st.sidebar.radio('', pages)

####################################################################
### PAGE 1 - Pr√©sentation du projet Ephesus
####################################################################

if direction == pages[0]:

    presentation1 = Image.open('images/PresentationPage1.PNG')
    presentation2 = Image.open('images/PresentationPage2.PNG')
    presentation3 = Image.open('images/PresentationPage3.PNG')

    if "persisted_variable" not in st.session_state:
        st.session_state.persisted_variable = 0

    columns_Page = st.columns(7)
    if columns_Page[6].button("‚ñ∂Ô∏è"):
        st.session_state.persisted_variable += 1

    if columns_Page[0].button("‚óÄÔ∏è"):
        st.session_state.persisted_variable -= 1

    # st.session_state.persisted_variable

    if st.session_state.persisted_variable == 0:
        st.image(presentation1, use_column_width=True)

    if st.session_state.persisted_variable == 1 :
        st.image(presentation2, use_column_width=True)

    if st.session_state.persisted_variable == 2 :
        st.image(presentation3, use_column_width=True)


    # html_code = '''
    #    <a target="_blank" href="https://geoffroygit.github.io/ephesus/notebooks/Ephesus.slides.html">
    #    <img src="https://raw.githubusercontent.com/JulianBreaud/ephesusWeb/master/images/fullscreen.png" /></a>
    #    <iframe width="100%" height="550" scrolling="yes" frameborder="no"
    #    allowfullscreen src="https://geoffroygit.github.io/ephesus/notebooks/Ephesus.slides.html"></iframe>
    #        '''
    # components.html(html_code, height = 600)

####################################################################
### PAGE 2 - DEMO
####################################################################

elif direction == pages[1]:

    # initialise session state
    if "button_audio2text_pressed" not in st.session_state:
        st.session_state.button_audio2text_pressed = False

    def run_models(text):

        # api url
        api_base_url = "https://ephesus-api-3d2vvkkptq-ew.a.run.app/"

        colors = {
                "Treatment" : "#99CCFF",
                "Cotation" : "#444444", #hors palette
                "Date" : "#B2E7E8",
                "Time" : "#8FB9AA",
                "Duration" : "#F2D096",
                "Frequency" : "#ED895",
                "Location" : "#FFCC99", #hors palette
                }

        # identify entities
        predict_url = api_base_url + "predict"
        predict_params = {"sentence" : text}
        predict_response = requests.get(predict_url, params=predict_params)
        if predict_response.status_code == 200:
            predict_response = predict_response.json()
        else:
            predict_response = {} # (we need to better handle the errors)
        # create Doc() object from vocab bytes and doc bytes
        labels = predict_response["labels"]
        doc_bytes = base64.b64decode(predict_response["doc"])
        vocab_bytes = base64.b64decode(predict_response["vocab"])
        vocab = Vocab()
        vocab.from_bytes(vocab_bytes)
        doc = Doc(vocab).from_bytes(doc_bytes)

        # show entities on screen
        visualize_ner(doc, labels=labels,
                    show_table = False,
                    title = "",
                    colors = colors)

        # feed entities to the models for treatment, date, time, location
        # list entities
        entities = [(str(ent), ent.label_) for ent in doc.ents]

        endpoints = {
            "Treatment" : "treatment",
            "Date" : "date",
            "Time" : "time",
            "Location" : "location",
            }

        columns_models = st.columns(len(entities))

        for i, item in enumerate(entities):
            if item[1] in endpoints:
                url_full = api_base_url + endpoints[item[1]]
            params = {"sentence" : item[0]}
            # api call
            response = requests.get(url_full, params=params)
            if response.status_code == 200:
                response_api = response.json()

                # show api response on screen
                #columns_models[i].markdown(f"#### {item[1]}")
                #columns_models[i].markdown(f"##### {item[0]}")
                color = colors[item[1]]
                for key, val in response_api.items():
                    columns_models[i].markdown(
                        f'<p style="background-color: {color}">{key} : {val}</p>',
                        unsafe_allow_html=True)

    def run_transcription():
        # Text of the memo (can be changed by the user)
        text = st.text_area("", memo)
        # run the models
        run_models(text)

    # Son du M√©mo
    st.markdown("""
        ### R√©alisation d'un m√©mo vocal par le personnel soignant
    """)
    # create columns to put the audio and the button side by side
    columns = st.columns(2)
    # load audio file
    audio_file = open('audio/Prise_de_sang.m4a', 'rb')
    audio_bytes = audio_file.read()
    columns[0].audio(audio_bytes, format='audio/ogg')
    # text transcript
    memo = "Prise de sang √† domicile le samedi 26 f√©vrier √† 8h15 par Amandine."

    if not st.session_state.button_audio2text_pressed:
        # show button transcription
        if columns[1].button("Transcription du m√©mo"):
            st.session_state.button_audio2text_pressed = True
            run_transcription()
    else:
        run_transcription()


# ####################################################################
# ### PAGE 3 - RUN
# ### on importe l'ensemble des translations et on lance le mod√®le et on obtient un rapport d'√©x√©cution
# ####################################################################

# elif direction == pages[2]:

#     st.markdown("""
#     # R√©cup√©ration de plusieurs m√©mos

#     """)

#     st.markdown("""
#         ### Partie 1 - R√©cup√©ration des m√©mos retranscrits :
#     """)

#     rep = st.text_input('Les memos sont dans le repertoire :', "raw_data/input_json")

#     LOCAL_PATH =str(rep)

#     # r√©cup√©ration des noms des fichiers output translation des memos vocaux
#     fichiers = [fichier for fichier in listdir(LOCAL_PATH) if isfile(join(LOCAL_PATH, fichier))]

#     data = []
#     for fichier in fichiers :
#         lib_fichier = LOCAL_PATH + "/" + fichier
#         with open(lib_fichier) as mon_fichier:
#             data.append(json.load(mon_fichier))

#     # r√©cup√©ration seulement de la phrase = sentence du m√©mo
#     data = [data[i]["Translation"] for i in range(len(data))]

#     # on √©crit une ligne vide pour la pr√©sentation
#     st.write("")

#     if len(data) > 1 :
#         st.write(f"{len(data)} translations trouv√©es : ")
#     else :
#         st.write(f"{len(data)} translation trouv√©e : ")

#     for i in range(len(data)) :
#         st.write(data[i])

#     st.markdown("""
#         ### Partie 2 - Lancement de l'analyse :
#     """)
#     if st.button("GO"):
#             # print is visible in the server output, not in the page
#             print('button clicked!')
#             st.write('Analyse lanc√©e üéâ')

#             # url de l'api
#             url = 'https://ephesus-api-3d2vvkkptq-ew.a.run.app/test'

#             st.markdown("""
#                             ### Partie 3 - Les r√©sultats :
#                             """)

#             for i in range(len(data)) :

#                 params = {
#                     "sentence" : data[i]
#                     }

#                 # retrieve the response
#                 response = requests.get(
#                     url,
#                     params=params
#                 )

#                 st.write('Phrase ' + str(i) + " :")

#                 if response.status_code == 200:
#                     response_api = response.json().get("entities", "not found")
#                     response_api = tuple(tuple(i) if type(i)==type([]) else i for i in response_api)
#                     annotated_text(*response_api)

#                 st.write("")

#             st.markdown("""
#                         ### Partie 4 - Le rapport d'ex√©cution :
#                         """)

#             col1, col2 = st.columns(2)
#             col1.metric("Nombre de documents lus", len(data), "")
#             col2.metric("Taux de reconnaissances", "80%", "")

#             # rapport d‚Äôex√©cution : le nombre de rejet, taux de d√©tections, de reconnaissance

# ####################################################################
# ### PAGE 4 - FIN
# ####################################################################

# else:
#     '''
#     # Merci pour votre √©coute.
#     # Avez-vous des questions ?
#     '''
