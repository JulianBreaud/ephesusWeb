
####################################################################
### IMPORTS
####################################################################

from re import S
import streamlit as st
import numpy as np
import pandas as pd
import requests
from PIL import Image
from annotated_text import annotated_text
import streamlit.components.v1 as components

import os
import json
from os import listdir
from os.path import isfile, join

import spacy
from spacy_streamlit import visualize, visualize_ner, visualize_textcat, visualize_tokens, process_text

from spacy.vocab import Vocab
from spacy.tokens import Doc
import base64

####################################################################
### SIDEBAR & CONFIG
####################################################################

st.set_page_config(
            page_title="Projet Ephesus", # => Quick reference - Streamlit
            page_icon="",#on a choisi le logo standard mais on peut mettre au chose "üêç",
            layout="wide",
            initial_sidebar_state="auto") # collapsed


image = Image.open('images/wagon.png')
st.sidebar.image(image, caption='Le Wagon', use_column_width=False)
st.sidebar.markdown("")

direction = st.sidebar.radio('', ('Projet Ephesus', 'D√©mo', 'Run', 'Et pour finir'))

####################################################################
### PAGE 1 - Pr√©sentation du projet Ephesus
####################################################################

if direction == 'Projet Ephesus':


    html_code = '''
        <a target="_blank" href="https://geoffroygit.github.io/ephesus/notebooks/Ephesus.slides.html">
        <img src="https://raw.githubusercontent.com/JulianBreaud/ephesusWeb/master/images/fullscreen.png" /></a>
        <iframe width="100%" height="550" scrolling="yes" frameborder="no"
        allowfullscreen src="https://geoffroygit.github.io/ephesus/notebooks/Ephesus.slides.html"></iframe>
            '''
    components.html(html_code, height = 600)

####################################################################
### PAGE 2 - DEMO
####################################################################

elif direction == 'D√©mo':

    st.markdown("""
    # D√©mo

    """)

    # Son du M√©mo
    st.markdown("""
        ### R√©alisation d'un m√©mo vocal par une infirmi√®re :
    """)
    st.write("")
    audio_file = open('audio/Prise_de_sang.m4a', 'rb')
    audio_bytes = audio_file.read()
    st.audio(audio_bytes, format='audio/ogg')

    # Translation du m√©mo
    st.markdown("""
        ### Transcription du m√©mo :
    """)
    text = st.text_area("", "Prise de sang √† domicile le samedi 26 f√©vrier √† 8h15 par amandine.")

    # identification des labels
    st.markdown("""
        ### Analyse :
    """)

    #----------------------------------------------------#
    #nlp = spacy.load("models/model_full/model-best")
    #doc = nlp(text)
    # replace the two lines of code above by an API call:
    predict_url = "https://ephesus-api-3d2vvkkptq-ew.a.run.app/predict"
    predict_params = {"sentence" : text}
    predict_response = requests.get(predict_url, params=predict_params)
    if predict_response.status_code == 200:
        predict_response = predict_response.json()
    else:
        predict_response = {} # (we need to better handle the errors)
    # create Doc() object from vocab bytes and doc bytes
    labels = predict_response["labels"]
    doc_bytes = base64.b64decode(predict_response["doc"])
    vocab_bytes = base64.b64decode(predict_response["vocab"])
    vocab = Vocab()
    vocab.from_bytes(vocab_bytes)
    doc = Doc(vocab).from_bytes(doc_bytes)
    #----------------------------------------------------#


    visualize_ner(doc, labels=labels,
    show_table = False,
    title = "",
    colors = {
        "Treatment" : "#99CCFF",
        "Cotation" : "#444444", #hors palette
        "Date" : "#B2E7E8",
        "Time" : "#8FB9AA",
        "Duration" : "#F2D096",
        "Frequency" : "#ED895",
        "Location" : "#FFCC99", #hors palette
        }
        )

    # Codage des labels
    st.markdown("""
        ### Traitement :
    """)

    liste = []
    for index, ent in enumerate(doc.ents):
        liste.append((str(doc.ents[index]), ent.label_))

    # url de l'api
    url = 'https://ephesus-api-3d2vvkkptq-ew.a.run.app/'

    endpoints = {
        "Treatment" : "treatment",
        "Date" : "date",
        "Time" : "time",
        "Location" : "location",
        }

    st.write("Nombre d'√©l√©ments d√©tect√©s : " + str(len(liste)))

    for item in liste:
        if item[1] in endpoints:
            url_full = url + endpoints[item[1]]

        st.write(item[1] + " : " + item[0])

        params = {
            "sentence" : item[0]
            }

        # retrieve the response
        response = requests.get(
            url_full,
            params=params
        )



        if response.status_code == 200:
            response_api = response.json()

            df = pd.DataFrame(data = [response_api.values()],
                columns=response_api.keys()
                )

            # CSS to inject contained in a string
            hide_dataframe_row_index = """
                        <style>
                            .row_heading.level0 {display:none}
                            .blank {display:none}
                        </style>
                        """

            # Inject CSS with Markdown
            st.markdown(hide_dataframe_row_index, unsafe_allow_html=True)

            st.dataframe(df)
#


####################################################################
### PAGE 3 - RUN
### on importe l'ensemble des translations et on lance le mod√®le et on obtient un rapport d'√©x√©cution
####################################################################

elif direction == 'Run':

    st.markdown("""
    # R√©cup√©ration de plusieurs m√©mos

    """)

    st.markdown("""
        ### Partie 1 - R√©cup√©ration des m√©mos retranscrits :
    """)

    rep = st.text_input('Les memos sont dans le repertoire :', "raw_data/input_json")

    LOCAL_PATH =str(rep)

    # r√©cup√©ration des noms des fichiers output translation des memos vocaux
    fichiers = [fichier for fichier in listdir(LOCAL_PATH) if isfile(join(LOCAL_PATH, fichier))]

    data = []
    for fichier in fichiers :
        lib_fichier = LOCAL_PATH + "/" + fichier
        with open(lib_fichier) as mon_fichier:
            data.append(json.load(mon_fichier))

    # r√©cup√©ration seulement de la phrase = sentence du m√©mo
    data = [data[i]["Translation"] for i in range(len(data))]

    # on √©crit une ligne vide pour la pr√©sentation
    st.write("")

    if len(data) > 1 :
        st.write(f"{len(data)} translations trouv√©es : ")
    else :
        st.write(f"{len(data)} translation trouv√©e : ")

    for i in range(len(data)) :
        st.write(data[i])

    st.markdown("""
        ### Partie 2 - Lancement de l'analyse :
    """)
    if st.button("GO"):
            # print is visible in the server output, not in the page
            print('button clicked!')
            st.write('Analyse lanc√©e üéâ')

            # url de l'api
            url = 'https://ephesus-api-3d2vvkkptq-ew.a.run.app/test'

            st.markdown("""
                            ### Partie 3 - Les r√©sultats :
                            """)

            for i in range(len(data)) :

                params = {
                    "sentence" : data[i]
                    }

                # retrieve the response
                response = requests.get(
                    url,
                    params=params
                )

                st.write('Phrase ' + str(i) + " :")

                if response.status_code == 200:
                    response_api = response.json().get("entities", "not found")
                    response_api = tuple(tuple(i) if type(i)==type([]) else i for i in response_api)
                    annotated_text(*response_api)

                st.write("")

            st.markdown("""
                        ### Partie 4 - Le rapport d'ex√©cution :
                        """)

            col1, col2 = st.columns(2)
            col1.metric("Nombre de documents lus", len(data), "")
            col2.metric("Taux de reconnaissances", "80%", "")

            # rapport d‚Äôex√©cution : le nombre de rejet, taux de d√©tections, de reconnaissance

####################################################################
### PAGE 4 - FIN
####################################################################

else:
    '''
    # Merci pour votre √©coute.
    # Avez-vous des questions ?
    '''
